{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Movie Recommender System Project\"\n",
        "authors: \"Jiajia Feng, Tess Ivinjack, Leslie Cervantes Rivera, Valerie De La Fuente\"\n",
        "date: 03-19-15\n",
        "editor: visual\n",
        "format: html\n",
        "code-copy: true\n",
        "execute:\n",
        "  message: false\n",
        "  warning: false\n",
        "  echo: false\n",
        "  cache: true\n",
        "---\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "### Objective\n",
        "\n",
        "This project aims to develop a movie recommendation system using data from The Movie Database (TMDb) API. By applying Python-based machine learning techniques, the system will analyze user preferences and suggest relevant movies. The goal is to create a personalized, efficient recommendation system that enhances content discovery for users.\n",
        "\n",
        "### Motivation\n",
        "\n",
        "In today's digital entertainment world, users are overwhelmed with content options, making personalized recommendations more essential than ever. Recommendation systems help by offering tailored suggestions, which improves user engagement and satisfaction. With platforms like Netflix and Hulu relying on data-driven algorithms, effective recommendation systems are crucial to enhancing viewer experience. Using data from an API like TMDb, which includes extensive movie data, allows for more accurate and relevant content suggestions. This allows for a more engaging and relevant user experience, fostering deeper interaction with the platform and greater satisfaction with the recommendations provided.\n",
        "\n",
        "### **Methodology**\n",
        "\n",
        "The movie recommendation system is implemented using Python and relies on data extracted from The Movie Database (TMDb) API to ensure access to the most up-to-date movie information. The system follows a hybrid approach using the cascade method, where content-based filtering is applied first to narrow down the dataset. This step filters movies based on their features, such as genres and other content-based movie information, to identify those similar to a userâ€™s interests.\n",
        "\n",
        "Once the dataset is refined, the filtered results are passed into the collaborative filtering script, if there is movie review data available for that film, which further analyzes patterns in user interactions to generate the final recommendations. By combining these two approaches, the system enhances recommendation accuracy and ensures that users receive relevant movie suggestions tailored to their preferences.\n",
        "\n",
        "### Data Description\n",
        "\n",
        "As aforementioned, the data is obtained using TMDb API. The data is extracted into two separate DataFrames, one content-based and one collaborative-based. The content-based DataFrame, `movie_content_df`, after undergoing all preprocessing and cleaning, includes the following variables: `movie_id`, `title`, `release_year`, `genre_ids`, `original_language`, `cast_names`, `watch_providers`, `rating_average`, and `vote_count`. The collaborative-based DataFrame, `movie_reviews_df`, after undergoing all preprocessing and cleaning, includes the following variables: `movie_id`, `user_rating`, and `user_id`. This DataFrame of movie reviews is also merged with `movies_df` to build the collaborative based recommender, which is just selecting a subset of the columns from `movie_content_df`. These columns are `movie_id`, `title`, `release_year`, `genre_ids`, `original_language`, and `vote_count`.\n",
        "\n",
        "The `movie_content_df` has 4,000 rows representing an observation for each of the 4,000 unique movies. The `movie_reviews_df` has 9,602 rows representing a user rating for 2,540 unique movies. Due to time and computing power limitations on our local computers, we weren't able to retrieve more than this amount of movie reviews, which results in there being 1,668 unique movies that are in both the `movie_content_df` and the `movie_reviews_df`, and 2,332 movies that we have content information on, but no user reviews. This discrepancy between the datasets is what lead to the pipeline that was implemented for the hybrid recommender approach, which will be explained in further detail later on.\n",
        "\n",
        "### API Data Retrieval\n",
        "\n",
        "To use the TMDb API, users must create an account on [The Movie Database website](https://www.themoviedb.org/) and generate a personal authentication key. This key is required to authenticate API requests and obtain data. Content-based filtering and collaborative-based filtering have their own respective data retrieval scripts. Both retrieval scripts include a delay between requests to avoid hitting TMDb's rate limit.\n",
        "\n",
        "#### Content-based filtering\n"
      ],
      "id": "4322f9ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Loading necessary packages\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "api_key = \"d3e8d7fcb94be031986259192b4fdfb0\"\n",
        "\n",
        "# Base URLs\n",
        "url = \"https://api.themoviedb.org/3/movie/popular\"\n",
        "credits_url_template = \"https://api.themoviedb.org/3/movie/{}/credits\"\n",
        "providers_url_template = \"https://api.themoviedb.org/3/movie/{}/watch/providers\"\n",
        "\n",
        "# Number of pages to retrieve\n",
        "total_pages = 200\n",
        "all_movies = []\n",
        "\n",
        "# Fetch popular movies\n",
        "for page in range(1, total_pages + 1):\n",
        "    parameters = {\"api_key\": api_key, \"page\": page}\n",
        "    response = requests.get(url, params=parameters)\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        movies = data[\"results\"]\n",
        "        \n",
        "        for movie in movies:\n",
        "            movie[\"movie_id\"] = movie.pop(\"id\")  # Rename 'id' to 'movie_id'\n",
        "            movie[\"rating_average\"] = movie.pop(\"vote_average\")  # Rename 'vote_average' to 'rating_average'\n",
        "            \n",
        "            # Get cast names\n",
        "            credits_url = credits_url_template.format(movie[\"movie_id\"])\n",
        "            credits_response = requests.get(credits_url, params={\"api_key\": api_key})\n",
        "            if credits_response.status_code == 200:\n",
        "                credits_data = credits_response.json()\n",
        "                cast_names = {cast_member[\"name\"] for cast_member in credits_data.get(\"cast\", [])} \n",
        "                movie[\"cast_names\"] = \", \".join(cast_names)  \n",
        "            else:\n",
        "                movie[\"cast_names\"] = None\n",
        "            \n",
        "            # Get watch providers\n",
        "            providers_url = providers_url_template.format(movie[\"movie_id\"])\n",
        "            providers_response = requests.get(providers_url, params={\"api_key\": api_key})\n",
        "            if providers_response.status_code == 200:\n",
        "                providers_data = providers_response.json()\n",
        "                provider_names = set()  # Store unique provider names\n",
        "                \n",
        "                for region, provider_info in providers_data.get(\"results\", {}).items():\n",
        "                    for category, providers_list in provider_info.items():\n",
        "                        if isinstance(providers_list, list):\n",
        "                            provider_names.update(provider[\"provider_name\"] for provider in providers_list)\n",
        "                \n",
        "                movie[\"watch_providers\"] = \", \".join(provider_names)\n",
        "            else:\n",
        "                movie[\"watch_providers\"] = None\n",
        "            \n",
        "            time.sleep(0.2)  # Short delay to avoid rate limiting\n",
        "        \n",
        "        all_movies.extend(movies)\n",
        "    else:\n",
        "        print(\"Error:\", response.status_code)\n",
        "    \n",
        "    time.sleep(0.5)\n",
        "    print(page)\n",
        "    \n",
        "# Convert to DataFrame\n",
        "movie_content_df = pd.DataFrame(all_movies)"
      ],
      "id": "5de1c3b0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The system queries the following TMDb API endpoints to gather relevant movie data:\n",
        "\n",
        "-   General Movie Metadata (`/movie/popular`, `/movie/{movie_id}`)\n",
        "\n",
        "    -   Retrieves a list of popular movies with their movie identification numbers, movie titles, genres, release dates, languages, and voting/popularity information.\n",
        "\n",
        "-   Cast Information (`/movie/{movie_id}/credits`)\n",
        "\n",
        "    -   Extracts key actors from each movie.\n",
        "\n",
        "-   Watch Providers (`movie/{movie_id}/watch/providers`)\n",
        "\n",
        "    -   Obtains a list of all available streaming service platforms for each movie.\n",
        "\n",
        "#### Collaborative-based filtering\n"
      ],
      "id": "83cb1934"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load necessary packages\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "api_key = \"d3e8d7fcb94be031986259192b4fdfb0\"\n",
        "\n",
        "# Base URLs\n",
        "popular_movies_url = \"https://api.themoviedb.org/3/movie/popular\"\n",
        "reviews_url_template = \"https://api.themoviedb.org/3/movie/{}/reviews\"\n",
        "\n",
        "# Number of pages to retrieve\n",
        "total_pages = 200 \n",
        "all_movies = []\n",
        "\n",
        "# Fetch popular movies\n",
        "for page in range(1, total_pages + 1):\n",
        "    parameters = {\"api_key\": api_key, \"page\": page}\n",
        "    response = requests.get(popular_movies_url, params=parameters)\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        all_movies.extend(data[\"results\"])\n",
        "    else:\n",
        "        print(\"Error:\", response.status_code)\n",
        "        break\n",
        "\n",
        "    time.sleep(0.5)  # Prevent rate-limiting\n",
        "    print(page)\n",
        "\n",
        "# Convert movies to DataFrame\n",
        "movies_df = pd.DataFrame(all_movies)\n",
        "\n",
        "# Fetch reviews for each movie\n",
        "reviews_data = []\n",
        "\n",
        "timeout_duration = 0.5\n",
        "\n",
        "for movie_id in movies_df[\"id\"]:\n",
        "    response = requests.get(reviews_url_template.format(movie_id), params={\"api_key\": api_key})\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        reviews = response.json().get(\"results\", [])\n",
        "        for review in reviews:\n",
        "            reviews_data.append({\n",
        "                \"movie_id\": movie_id,\n",
        "                \"author\": review.get(\"author\", \"Unknown\"),\n",
        "                \"user_rating\": review.get(\"author_details\", {}).get(\"rating\", None)  # Changed \"rating\" to \"user_rating\"\n",
        "            })\n",
        "    else:\n",
        "        print(\"Error:\", response.status_code)\n",
        "\n",
        "    time.sleep(0.5)\n",
        "\n",
        "# Convert reviews to DataFrame\n",
        "movie_reviews_df = pd.DataFrame(reviews_data)"
      ],
      "id": "05741a12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The system queries the following TMDb API endpoints to gather relevant movie data:\n",
        "\n",
        "-   Popular Movies List (`/movie/popular`)\n",
        "\n",
        "    -   Retrieves the same list of popular movies that was obtained in the content-based retrieval script, but only extracts movie identification numbers.\n",
        "\n",
        "-   User Ratings (`/movie/{movie_id}/reviews`)\n",
        "\n",
        "    -   Collects user-generated movie ratings on a scale from 1-10.\n",
        "\n",
        "## Data Cleaning and Feature Engineering\n",
        "\n",
        "After extracting all of the data from the online database, there are some preprocessing steps to be done so that the data is clean and in the correct format to move forward with the recommender system implementation. Each DataFrame has their own script for the tidying that is necessary.\n",
        "\n",
        "### Content-based filtering\n"
      ],
      "id": "dc23b917"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Creates the dictionary of genre IDs and names\n",
        "# Load necessary packages\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "api_key = \"d3e8d7fcb94be031986259192b4fdfb0\"\n",
        "\n",
        "# Base URL\n",
        "url = \"https://api.themoviedb.org/3/genre/movie/list\"\n",
        "\n",
        "# Set parameters like the page number and API key\n",
        "parameters = {\n",
        "    \"api_key\": api_key,\n",
        "    \"page\":1\n",
        "}\n",
        "\n",
        "# Make the GET request to fetch the data\n",
        "response = requests.get(url, params=parameters)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    genre_data = response.json()  # Convert response to JSON\n",
        "    genres = genre_data[\"genres\"]  # Extract the list of genres\n",
        "    genre_dict = {genre[\"id\"]: genre[\"name\"] for genre in genres}  # Create dictionary\n",
        "    print(genre_dict)  # Print the genre mapping\n",
        "\n",
        "else:\n",
        "    print(\"Error\", response.status_code)"
      ],
      "id": "b0e84443",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first step in preprocessing the content-based data is to create a dictionary that maps the genre identification numbers to its corresponding genre category.\n"
      ],
      "id": "b69ac98d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| echo: false\n",
        "\n",
        "movie_reviews_df = pd.read_csv('../data/movie_reviews_data.csv')\n",
        "movie_content_df = pd.read_csv('../data/movie_content_df.csv')\n",
        "movies_df = pd.read_csv('../data/movies_data.csv')\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "id": "d43da359",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load necessary packages\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "def genre_preprocessing(dataframe):\n",
        "    # Convert genre_ids to lists\n",
        "    dataframe['genre_ids'] = dataframe['genre_ids'].apply(ast.literal_eval)\n",
        "    \n",
        "    # Map genre_ids to genre names\n",
        "    dataframe['genre_ids'] = dataframe['genre_ids'].apply(lambda x: [genre_dict[genre_id] for genre_id in x])\n",
        "    \n",
        "    return dataframe\n",
        "\n",
        "\n",
        "def content_preprocessing(dataframe):\n",
        "      # Format genre_ids\n",
        "      dataframe = genre_preprocessing(dataframe)\n",
        "    \n",
        "      # Select necessary columns\n",
        "      dataframe = dataframe[['movie_id', 'title', 'release_date', 'genre_ids', 'original_language', 'cast_names', 'watch_providers', 'rating_average', 'vote_count']]\n",
        "      \n",
        "      return dataframe\n",
        "    \n",
        "# Apply the preprocessing function\n",
        "movie_content_df = content_preprocessing(movie_content_df)"
      ],
      "id": "225d2623",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code chunk above applies the genre dictionary to extract genre categories. It also retains relevant columns in the DataFrame.\n"
      ],
      "id": "338ab35f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load necessary packages\n",
        "import pandas as pd\n",
        "import pycountry # for languages convertion\n",
        "import pandas as pd\n",
        "movie_content_df.columns\n",
        "# Tidying `genre_ids` \n",
        "def clean_genre_ids(value):\n",
        "    if isinstance(value, list):  # If it's already a list, clean and join\n",
        "        return ', '.join(genre.strip() for genre in value)\n",
        "    elif isinstance(value, str) and value.startswith('c(') and value.endswith(')'):\n",
        "        # Handle string cases formatted like R's \"c(...)\"\n",
        "        genres = [genre.strip().strip('\"') for genre in value[2:-1].split(',')]\n",
        "        return ', '.join(genres)\n",
        "    return value  # Return as is if neither case\n",
        "\n",
        "    # Apply the function to genre_ids column\n",
        "movie_content_df['genre_ids'] = movie_content_df['genre_ids'].apply(clean_genre_ids)\n",
        "    # Check genre_ids missing and type\n",
        "movie_content_df['genre_ids'].isna().sum() # No missing data\n",
        "movie_content_df['genre_ids'].apply(type).value_counts() # All are string type\n",
        "\n",
        "# Tidying original language to be full word\n",
        "def convert_language_code(code):\n",
        "    try:\n",
        "        language = pycountry.languages.get(alpha_2=code)\n",
        "        return language.name\n",
        "    except:\n",
        "        return code  # no corresponding language, return original language code\n",
        "movie_content_df['original_language'] = movie_content_df['original_language'].apply(convert_language_code)\n",
        "movie_content_df[\"original_language\"] = movie_content_df[\"original_language\"].replace(\"cn\", \"Chinese\") # cn to Chinese\n",
        "movie_content_df[\"original_language\"] = movie_content_df[\"original_language\"].replace(\"xx\", \"Unknown\") # xx to Unknown\n",
        "    \n",
        "# Editing data types\n",
        "movie_content_df['rating_average'] = pd.to_numeric(movie_content_df['rating_average'], errors='coerce')\n",
        "movie_content_df['rating_average'] = movie_content_df['rating_average'].round(0).astype(int) # vote_average to round\n",
        "movie_content_df['vote_count'] = pd.to_numeric(movie_content_df['vote_count'], errors='coerce')\n",
        "\n",
        "# Creating a `release_year` column\n",
        "movie_content_df = movie_content_df.copy()  # Ensure movies_df is a separate DataFrame\n",
        "movie_content_df[\"release_date\"] = movie_content_df[\"release_date\"].astype(str)\n",
        "movie_content_df = movie_content_df[movie_content_df[\"release_date\"] != '']\n",
        "movie_content_df[\"release_year\"] = pd.to_numeric(movie_content_df[\"release_date\"].str[:4], errors = \"coerce\")\n",
        "movie_content_df = movie_content_df.drop(columns=[\"release_date\"])\n",
        "\n",
        "# Changing the `title` type\n",
        "  # Convert to pandas' new string type\n",
        "movie_content_df[\"title\"] = movie_content_df[\"title\"].astype(\"string\")\n",
        "  # Check the dtype again\n",
        "print(movie_content_df[\"title\"].dtype)\n",
        "    \n",
        "# Editing `cast_names`\n",
        "movie_content_df[\"cast_names\"] = movie_content_df[\"cast_names\"].replace(\"\", pd.NA)\n",
        "\n",
        "# Editing `watch_providers`\n",
        "movie_content_df[\"watch_providers\"] = movie_content_df[\"watch_providers\"].replace(\"\", pd.NA)\n",
        "\n",
        "# Reordering column names\n",
        "  # Define the new column order\n",
        "new_column_order = ['movie_id', 'title', 'release_year', 'genre_ids', 'original_language', 'cast_names', 'watch_providers', 'rating_average', 'vote_count']\n",
        "  # Reorganize columns in the DataFrame\n",
        "movie_content_df = movie_content_df[new_column_order]"
      ],
      "id": "373dd877",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following edits were made in the code chunk above:\n",
        "\n",
        "-   `genre_ids` is edited to be a cleaned, comma-separated string\n",
        "\n",
        "-   `original_language` is edited to display the full name of the language, not the abbreviation\n",
        "\n",
        "-   `release_year` is created from `release_date` and `release_date` is dropped from the DataFrame\n",
        "\n",
        "-   `cast_names` and `watch_providers` are edited to replace empty strings with `NA`\n",
        "\n",
        "-   All columns are checked to ensure correct data types\n",
        "\n",
        "-   Columns are reordered in the DataFrame for readability\n",
        "\n",
        "-   Missing values are retained in the DataFrame\n",
        "\n",
        "### Collaborative-based filtering\n"
      ],
      "id": "d5514ee0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "def genre_preprocessing(dataframe):\n",
        "    # Convert genre_ids to lists\n",
        "    dataframe['genre_ids'] = dataframe['genre_ids'].apply(ast.literal_eval)\n",
        "    \n",
        "    # Map genre_ids to genre names\n",
        "    dataframe['genre_ids'] = dataframe['genre_ids'].apply(lambda x: [genre_dict[genre_id] for genre_id in x])\n",
        "    \n",
        "    return dataframe\n",
        "    \n",
        "def collab_preproccesing(dataframe):\n",
        "      # Format genre_ids\n",
        "      dataframe = genre_preprocessing(dataframe)\n",
        "      \n",
        "      # Select necessary columns\n",
        "      dataframe = dataframe[['id', 'title', 'release_date', 'genre_ids', 'original_language', 'vote_count']]\n",
        "      \n",
        "      return dataframe\n",
        "\n",
        "# Apply the preprocessing function\n",
        "movies_df = collab_preproccesing(movies_df)"
      ],
      "id": "fdbb55d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin for the collaborative based preprocessing, a similar pipeline to what was used for content based is followed. The genre ids are mapped to genres names and the relevant columns are retained.\n"
      ],
      "id": "070dae21"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Creating a `user_id` column\n",
        "user_id_map = {}  # Dictionary to store author -> user_id mapping\n",
        "current_id = 1\n",
        "\n",
        "# Ensure 'user_id' column exists\n",
        "movie_reviews_df[\"user_id\"] = pd.NA  \n",
        "\n",
        "# Get valid indices\n",
        "valid_indices = movie_reviews_df[\"user_rating\"].notna() & (movie_reviews_df[\"user_rating\"] != \"\")\n",
        "\n",
        "# Store user IDs in a list to avoid modifying DataFrame during iteration\n",
        "user_ids = []\n",
        "\n",
        "for idx, author in movie_reviews_df.loc[valid_indices, \"author\"].items():\n",
        "    if author not in user_id_map:\n",
        "        user_id_map[author] = current_id\n",
        "        current_id += 1\n",
        "    user_ids.append((idx, user_id_map[author]))\n",
        "\n",
        "# Assign user IDs to the DataFrame\n",
        "for idx, user_id in user_ids:\n",
        "    movie_reviews_df.loc[idx, \"user_id\"] = user_id\n",
        "\n",
        "# Convert `user_id` to integers (nullable type to allow NaN)\n",
        "movie_reviews_df[\"user_id\"] = movie_reviews_df[\"user_id\"].astype(\"Int64\")\n",
        "\n",
        "# Drop the `author` column\n",
        "movie_reviews_df = movie_reviews_df.drop(columns=[\"author\"])"
      ],
      "id": "1beab295",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following edits were made in the code chunk above:\n",
        "\n",
        "-   `user_id`, a unique identification number, is assigned to each reviewer and is created from `author` and `author` is dropped from the DataFrame\n",
        "\n",
        "-   Missing values are retained in the DataFrame\n",
        "\n",
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "In this section, we are focusing on EDA to better understand the data. This is the stage where we are given insights into the structure and characteristics of the data, for instance missing values.\n",
        "\n",
        "### Variables\n"
      ],
      "id": "df8dab34"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "\n",
        "console = Console()\n",
        "\n",
        "table = Table(title = \"Movie Dataset Variables\", show_lines = True)\n",
        "\n",
        "table.add_column(\"Variable Name\", style = \"cyan\", justify = \"left\")\n",
        "table.add_column(\"Description\", style = \"magenta\", justify = \"left\")\n",
        "\n",
        "table.add_row('movie_id', 'Unique identifier of the movie.')\n",
        "table.add_row('title', 'Title of the movie.')\n",
        "table.add_row('release_year', 'The year the movie was released.')\n",
        "table.add_row('genre_ids', 'List of genres associated with a movie.')\n",
        "table.add_row('original_language', 'Original language of the movie.')\n",
        "table.add_row('cast_names', 'List of actors in the movie.')\n",
        "table.add_row('watch_providers', 'Streaming platforms where the movie is available.')\n",
        "table.add_row('rating_average', 'A quantitative assessment of the overall quality of a movie.')\n",
        "table.add_row('vote_count', 'The total number of people who voted for the movie.')\n",
        "table.add_row('author', 'Unique identifier for the user.')\n",
        "table.add_row('user_rating', 'Rating given by user.')\n",
        "console.print(table)"
      ],
      "id": "a401cfbf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Missing Data\n"
      ],
      "id": "ef4b6eee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import warnings \n",
        "warnings.simplefilter(action ='ignore', category = FutureWarning)\n",
        "\n",
        "#plotting missing values for movie_content_df\n",
        "  plt.figure(figsize = (18,8))\n",
        "  sns.heatmap(movie_content_df.isnull(), cmap = \"Purples\")\n",
        "  plt.xlabel('Variables')\n",
        "  plt.ylabel('Column Number')\n",
        "  plt.xticks(rotation = 80)\n",
        "  plt.title('Missing Values for movie_content_df')\n",
        "  plt.subplots_adjust(bottom = 0.25)\n",
        "  plt.show()"
      ],
      "id": "0d95a943",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset `movie_content_df` is missing some observations in `genre_ids`, `cast_names`, and `watch_providers`. It appears that movies missing watch provider information are those that have been newly released.\n"
      ],
      "id": "e910c227"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#plotting missing values for movie_reviews_df\n",
        "plt.figure(figsize = (18,8))\n",
        "sns.heatmap(movie_reviews_df.isnull(), cmap = \"Purples\")\n",
        "plt.xlabel('Variables')\n",
        "plt.ylabel('Column Number')\n",
        "plt.title('Missing Values for movie_reviews_df')\n",
        "plt.subplots_adjust(bottom = 0.25)\n",
        "plt.show()"
      ],
      "id": "f8718efb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While in the `movie_reviews_df`, it is missing a majority of `user_rating`. It could be that users either did not watch the movie or chose to skip rating it.\n",
        "\n",
        "#### Popular Genres\n"
      ],
      "id": "9da71f25"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#separating genres and exploding\n",
        "movie_content_df['genre_ids'] = movie_content_df['genre_ids'].fillna('').astype(str)\n",
        "movie_content_df['genre_list'] = movie_content_df['genre_ids'].apply(lambda x: [genre.strip() for genre in x.split(',')])\n",
        "movies_exploded = movie_content_df.explode('genre_list')\n",
        "\n",
        "#bar chart for genre counts\n",
        "genre_counts = movies_exploded['genre_list'].value_counts()\n",
        "plt.figure(figsize = (12, 6))\n",
        "sns.barplot(x = genre_counts.index[:10], y = genre_counts.values[:10], palette = \"coolwarm\")\n",
        "plt.xticks(rotation = 45)\n",
        "plt.xlabel('Genre')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Popular Genres')\n",
        "plt.subplots_adjust(bottom = .25)\n",
        "plt.show()"
      ],
      "id": "80bb09c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "About 1600 of movies are categorized under Drama, making it the most popular genre. Comedy and Thriller follow closely behind with approximately 1400 and 1000 counts. This suggests that these genres dominate the dataset, potentially representing popular trends in the movie industry.\n",
        "\n",
        "#### Popular Movie Languages\n"
      ],
      "id": "9984b12b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#countplot for languages\n",
        "plt.figure(figsize = (12, 6))\n",
        "sns.countplot(y = 'original_language', data = movie_content_df, order = movie_content_df['original_language'].value_counts(ascending = False).index[:5])\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Language')\n",
        "plt.title('Top 5 Movie Languages')\n",
        "plt.subplots_adjust(left = .25)\n",
        "plt.show()"
      ],
      "id": "680c50a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the majority of the movies in our dataset have their original language in English, with a count of approximately 2,800. This is expected as English is the dominant language in the film industry. The next popular languages are French and Japanese, with approximately 500 and 100 counts. France is considered as the origin of film and the Cannes Film Festival is French-based, while Japanese films are distinct in style which set apart from other films.\n",
        "\n",
        "#### Popular Actors\n"
      ],
      "id": "96f19e01"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#separating actors and exploding\n",
        "movie_content_df['actors_list'] = movie_content_df['cast_names'].str.split(',')\n",
        "movies_exploded = movie_content_df.explode('actors_list')\n",
        "\n",
        "#bar chart for actor counts\n",
        "actors_count = movies_exploded['actors_list'].value_counts().sort_values(ascending = False)\n",
        "plt.figure(figsize = (12, 6))\n",
        "sns.barplot(x = actors_count.values[:15], y = actors_count.index[:15], orient = 'h', color = \"skyblue\")\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Actor')\n",
        "plt.title('Common Actors')\n",
        "plt.yticks(rotation = 0)\n",
        "plt.subplots_adjust(left = .3)\n",
        "plt.show()"
      ],
      "id": "34043bb0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see \"Jr.\" is the most common actor in our movie dataset with a count of approximately 85. We do not know who exactly \"Jr.\" is, but we believe the name was cut when retrieving the data. Other actors such as Samuel L. Jackson, and Bruce Willis were also common with counts of approximately 45 and 42.\n",
        "\n",
        "#### Providers\n"
      ],
      "id": "17e494c4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "movie_content_df['providers_list'] = movie_content_df['watch_providers'].str.split(',')\n",
        "movies_exploded = movie_content_df.explode('providers_list')\n",
        "\n",
        "# Count the occurrences of each provider\n",
        "provider_counts = movies_exploded['providers_list'].value_counts()\n",
        "\n",
        "# Bar chart for the top providers\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=provider_counts.values[:15], y=provider_counts.index[:15], color=\"pink\")\n",
        "plt.xlabel('Number of Movies Available')\n",
        "plt.ylabel('Provider')\n",
        "plt.title('Most Available Streaming Providers')\n",
        "plt.subplots_adjust(left=0.4)\n",
        "plt.show()"
      ],
      "id": "7ca3f179",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our top providers, 'Apple TV', 'Google Play Movies', dominate the dataset, offering approximately 3,000 movies. This reflects their strong presence in the streaming market. While these providers account for a significant portion of the dataset, YouTube and Microsoft Store offer approximately 2,500+ movies, highlighting the growing presence of digital platforms.\n",
        "\n",
        "#### Reviewers\n"
      ],
      "id": "25bb02a9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#counting how many times an author reviewed movies\n",
        "user_review_counts = movie_reviews_df['author'].value_counts()\n",
        "\n",
        "# Bar chart for top reviewers\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=user_review_counts.values[:10], y=user_review_counts.index[:10], color=\"darkviolet\")\n",
        "plt.xlabel('Number of Reviews')\n",
        "plt.ylabel('Author')\n",
        "plt.title('Top 10 Users with Most Reviews')\n",
        "plt.subplots_adjust(left=0.4)\n",
        "plt.show()"
      ],
      "id": "3f09a676",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'CinemaSerf' is our top reviewer, contributing reviews for approximately 300 movies. Following closely behind are 'r96sk' and 'Manuel SÃ£o Bento' with approximately 170 and 110 movie reviews. It would be interesting to explore if their reviews are concentrated in particular genres or if they are more diverse.\n",
        "\n",
        "## Modeling Approach\n",
        "\n",
        "### Content-Based Filtering\n",
        "\n",
        "Content-based filtering recommends movies based on their features rather than user interactions. We use TF-IDF vectorization to encode movie attributes and compute similarity using cosine similarity and linear kernel similarity.\n",
        "\n",
        "**Implementation Steps:**\\\n",
        "1. **Cosine Similarity**\n",
        "\n",
        "-   Combine `genre_ids`, `cast_names`, and `watch_providers` into a single text feature\n",
        "-   Apply TF-IDF vectorization to convert text into numerical vectors\n",
        "-   Compute cosine similarity to measure the pairwise similarity between movies\n"
      ],
      "id": "7ba861ec"
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| echo: false\n",
        "\n",
        "import pandas as pd\n",
        "file_path = \"~/Desktop/Pstat134/Pstat134-Movie-Recommender-System/data_final/movie_contents copy.csv\"\n",
        "\n",
        "movie_content_df = pd.read_csv(file_path)"
      ],
      "id": "c82c6909",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Combine relevent features\n",
        "movie_content_df[\"combined_features\"] = (\n",
        "    movie_content_df[\"genre_ids\"].fillna(\"\").str.replace(\",\", \" \") + \" | \" +  \n",
        "    movie_content_df[\"cast_names\"].fillna(\"\").str.replace(\",\", \" \") + \" | \" +  \n",
        "    movie_content_df[\"watch_providers\"].fillna(\"\").str.replace(\",\", \" \")\n",
        ")\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", min_df=2)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(movie_content_df[\"combined_features\"])\n",
        "print(\"TF-IDF Matrix Shape:\", tfidf_matrix.shape)\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "print(\"Cosine Similarity Matrix Shape:\", cosine_sim.shape)\n",
        "print(\"Sample Cosine Similarity Scores:\\n\", cosine_sim[:5, :5])"
      ],
      "id": "9a4b68a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2\\. **Linear Kernel Similarity**\n",
        "\n",
        "-   Integrate `rating_average` and `vote_count` with linear kernel similarity\n",
        "-   Normalize numeric features and concatenate them with TF-IDF vectors\n",
        "-   Compute linear kernel similarity\n"
      ],
      "id": "0a76219b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# TF-IDF\n",
        "movie_content_df[\"combined_features\"] = (\n",
        "    movie_content_df[\"genre_ids\"].fillna(\"\").str.replace(\",\", \" \") + \" | \" +\n",
        "    movie_content_df[\"cast_names\"].fillna(\"\").str.replace(\",\", \" \") + \" | \" +\n",
        "    movie_content_df[\"watch_providers\"].fillna(\"\").str.replace(\",\", \" \")\n",
        ")\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", min_df=2)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(movie_content_df[\"combined_features\"])\n",
        "\n",
        "# add numeric features(need standardization)\n",
        "scaler = MinMaxScaler()\n",
        "numeric_features = movie_content_df[[\"rating_average\", \"vote_count\"]].fillna(0)\n",
        "numeric_matrix = scaler.fit_transform(numeric_features)\n",
        "\n",
        "# integrate TFIDF and numeric features\n",
        "final_matrix = np.hstack((tfidf_matrix.toarray(), numeric_matrix))\n",
        "\n",
        "# Linear Kernel similarity\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "linear_sim = linear_kernel(final_matrix, final_matrix)\n",
        "\n",
        "print(\"Linear Kernel Similarity Matrix Shape:\", linear_sim.shape)\n",
        "print(\"Sample Linear Kernel Similarity Scores:\\n\", linear_sim[:5, :5])"
      ],
      "id": "8d152a64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3\\. **Movie Recommendation System**\n",
        "\n",
        "-   Fuzzy matching ensures accurate title recognition\n",
        "\n",
        "-   Retrieve the most similar movies using\n",
        "\n",
        "    -   **Cosine Similarity (text only)**\n",
        "    -   **Linear Kernel Similarity (text + numeric)**\n"
      ],
      "id": "e0d97860"
    },
    {
      "cell_type": "code",
      "metadata": {
        "md-indent": "    "
      },
      "source": [
        "from difflib import get_close_matches\n",
        "\n",
        "def content_based_movie_recs(movie_title, movie_content_df, cosine_sim, top_n=11):\n",
        "    # prepprocess input: remove space and lowercase\n",
        "    clean_title = movie_title.strip().lower()\n",
        "\n",
        "    # preprocess movie title\n",
        "    movie_content_df[\"clean_title\"] = movie_content_df[\"title\"].str.strip().str.lower()\n",
        "\n",
        "    # find the most similar movie\n",
        "    possible_matches = get_close_matches(clean_title, movie_content_df[\"clean_title\"], n=1, cutoff=0.7)\n",
        "\n",
        "    \n",
        "    if possible_matches:\n",
        "        clean_title = possible_matches[0]\n",
        "\n",
        "    \n",
        "    movie_idx = movie_content_df[movie_content_df[\"clean_title\"] == clean_title].index\n",
        "\n",
        "    if movie_idx.empty:\n",
        "        return f\"Movie '{movie_title.strip()}' not found. Please check the title.\"\n",
        "\n",
        "\n",
        "    movie_idx = movie_idx[0]\n",
        "\n",
        "   \n",
        "    similarity_scores = list(enumerate(cosine_sim[movie_idx]))\n",
        "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
        "\n",
        "   \n",
        "    top_movies = similarity_scores[1:top_n+1]\n",
        "\n",
        "    \n",
        "    recommendations = movie_content_df.iloc[[i[0] for i in top_movies]][[\"title\", \"genre_ids\", \"rating_average\"]]\n",
        "\n",
        "    print(f\"\\nðŸŽ¬ Using matched movie: {movie_content_df.iloc[movie_idx]['title']}\")\n",
        "    print(f\"\\nðŸ“Œ Top 10 movies similar to '{movie_title.strip()}':\")\n",
        "    for i, row in enumerate(recommendations.itertuples(), start=1):\n",
        "        print(f\"{i}. {row.title} (Genre: {row.genre_ids}, Rating: {row.rating_average})\")\n",
        "\n",
        "    return recommendations"
      ],
      "id": "a3049111",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "recommendations1 = content_based_movie_recs(\"The Gorgee\", movie_content_df, cosine_sim)\n",
        "recommendations2 = content_based_movie_recs(\"Paprika\", movie_content_df, cosine_sim)"
      ],
      "id": "adc0a817",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from difflib import get_close_matches\n",
        "\n",
        "def content_based_movie_recs_linear(movie_title, movie_content_df, linear_sim, top_n=10):\n",
        "    # prepprocess input: remove space and lowercase\n",
        "    clean_title = movie_title.strip().lower()\n",
        "\n",
        "    # preprocess movie title\n",
        "    movie_content_df[\"clean_title\"] = movie_content_df[\"title\"].str.strip().str.lower()\n",
        "\n",
        "    # find the most similar movie\n",
        "    possible_matches = get_close_matches(clean_title, movie_content_df[\"clean_title\"], n=1, cutoff=0.7)\n",
        "\n",
        "\n",
        "    if possible_matches:\n",
        "        clean_title = possible_matches[0]\n",
        "    else:\n",
        "        return f\"Movie '{movie_title.strip()}' not found. Please check the title.\"\n",
        "\n",
        "\n",
        "    movie_idx = movie_content_df[movie_content_df[\"clean_title\"] == clean_title].index\n",
        "    if movie_idx.empty:\n",
        "        return f\"Movie '{movie_title.strip()}' not found. Please check the title.\"\n",
        "\n",
        "    movie_idx = movie_idx[0]\n",
        "\n",
        "\n",
        "    similarity_scores = list(enumerate(linear_sim[movie_idx]))\n",
        "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Top 10\n",
        "    top_movies = similarity_scores[1:top_n+1]\n",
        "\n",
        "  \n",
        "    recommendations = movie_content_df.iloc[[i[0] for i in top_movies]][[\"title\", \"genre_ids\", \"rating_average\"]]\n",
        "\n",
        "    print(f\"\\nðŸŽ¬ Using matched movie: {movie_content_df.iloc[movie_idx]['title']}\")\n",
        "    print(f\"\\nðŸ“Œ Top 10 movies similar to '{movie_title.strip()}':\")\n",
        "    for i, row in enumerate(recommendations.itertuples(), start=1):\n",
        "        print(f\"{i}. {row.title} (Genre: {row.genre_ids}, Rating: {row.rating_average})\")\n",
        "\n",
        "    return recommendations"
      ],
      "id": "fb7891eb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "recommended_movies_linear1 = content_based_movie_recs_linear(\"The Gorgee\", movie_content_df, linear_sim)\n",
        "recommended_movies_linear2 = content_based_movie_recs_linear(\"paprika\", movie_content_df, linear_sim)"
      ],
      "id": "b97473ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The cosine similarity method is effective in capturing textual feature similarity, making it ideal for recommending movies with similar genres, cast, or streaming providers. However, it does not incorporate numerical factors such as popularity. The linear kernel similarity method, on the other hand, integrates `rating_average` and `vote_count`, leading to more balanced recommendations that consider both textual and numerical attributes.\n",
        "\n",
        "### Collaborative Filtering\n",
        "\n",
        "Collaborative filtering on the other hand is a method that recommends movies to users based on ratings. In this project, it looks at whatever movie the user is looking for recommendations for and suggests the top most similar movies with regard to how other users have rated it. So if two movies have been given very similar rating patterns from users, then they are likely to be recommended for each other. There is another kind of collaborative filtering, that instead compares the users ratings for other movies, and recommends movies that other users who have similar rating patterns to them had enjoyed, but since we only had access to past user ratings, this project focuses on the first kind of collaborative filtering.\n",
        "\n",
        "**Implementation Steps:**\\\n",
        "1. **Get user-item matrix**\n",
        "\n",
        "-   Pivot the `movies_merged` data frame which has information on movies and their ratings across different users\n",
        "    -   Every row represents a movie\n",
        "    -   Every column represents a reviewer\n",
        "    -   Values are the users rating of that movie\n",
        "\n",
        "2\\. **Fit K-Nearest Neighbors model**\n",
        "\n",
        "-   Fit a KNN model that uses cosine similarity as the distance metric\n",
        "-   Input is the Compressed Sparse Row (CSR) matrix of the user-item matrix\n",
        "\n",
        "3\\. **Extract top n recommendations**\n",
        "\n",
        "-   Given a movie title, KNN finds the top n movies with similar user ratings\n",
        "\n",
        "-   Collects movie information like genre, rating, and where users can stream it\n",
        "\n",
        "-   Prints the information for the user\n"
      ],
      "id": "2d31176b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| echo: false\n",
        "movie_reviews_df = pd.read_csv('../data/movie_reviews_data.csv')\n",
        "movie_content_df = pd.read_csv('../data/movie_content_processed.csv')\n",
        "movies_df = pd.read_csv('../data/movies_data.csv')\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "id": "de35d738",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Join the movies and reviews dataframes\n",
        "movies_merged = pd.merge(movies_df, movie_reviews_df, left_on='id', right_on='movie_id')\n",
        "\n",
        "# Pivot so that rows are movies, columns are a user, and values are ratings\n",
        "movies_pivot = movies_merged.pivot_table(index=\"title\",columns=\"id\",values=\"user_rating\").fillna(0)\n",
        "\n",
        "# Create Compressed Sparse Row (CSR) matrix\n",
        "movies_matrix = csr_matrix(movies_pivot.values)\n",
        "\n",
        "# Fit KNN model with cosine similarity as distance metric\n",
        "knn = NearestNeighbors(metric = \"cosine\", algorithm = \"brute\")\n",
        "knn.fit(movies_matrix)"
      ],
      "id": "95f1b908",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code above executes steps one and two of the collaborative recommendation. It prepares the data to be fit by a K Nearest Neighbors model by transforming it into a CSR user-item matrix, and then proceeds to fit the model.\n"
      ],
      "id": "f4c66836"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def collaborative_based_movie_recs(title, movies_pivot, movies_merged, knn, num_recs=10):\n",
        "    # Check if movie is within dataset\n",
        "    if title not in movies_pivot.index:\n",
        "        return f\"Movie '{title}' not found in the dataset.\"\n",
        "      \n",
        "    # List only popular streaming services to include\n",
        "    popular_streaming_services = [\n",
        "    'Netflix', 'Amazon Prime Video', 'Hulu', 'Disney+', 'Apple TV', 'HBO Max', \n",
        "    'YouTube', 'Google Play Movies', 'Peacock', 'Paramount+',\n",
        "    'Max', 'Mubi', 'Amazon Video', 'Netflix basic with Ads', 'Hoopla', 'Vudu']\n",
        "    \n",
        "    # Get index of movie to get recommendations for\n",
        "    query_idx = movies_pivot.index.get_loc(title)\n",
        "    \n",
        "    # Given KNN model, find top 10 most similar movies based on user ratings\n",
        "    distances, indices = knn.kneighbors(movies_pivot.iloc[query_idx, :].values.reshape(1, -1), n_neighbors=num_recs + 1)\n",
        "    \n",
        "    recommendations = []\n",
        "    for i in range(1, len(indices.flatten())):  # Skip the first movie (it's itself)\n",
        "        # Extract movie name and information\n",
        "        movie_name = movies_pivot.index[indices.flatten()[i]]\n",
        "        movie_info = movie_content_df[movie_content_df['movie_id'] == movies_merged[movies_merged['title'] == movie_name]['movie_id'].iloc[0]]\n",
        "        \n",
        "        # Check that the movie exists in content DataFrame\n",
        "        if not movie_info.empty:\n",
        "            # Extract movie rating and genres\n",
        "            avg_rating = movie_info['rating_average'].iloc[0]\n",
        "            genre_ids = movie_info['genre_ids'].iloc[0]\n",
        "            # Convert genre ids to lists and join to make a string\n",
        "            if isinstance(genre_ids, str):\n",
        "                genre_ids = eval(genre_ids)\n",
        "            genre_str = \", \".join(map(str, genre_ids))\n",
        "            \n",
        "            # Collect watch provider information for each movie\n",
        "            watch_providers = movie_info['watch_providers'].iloc[0]\n",
        "            # Format info so it only contains the popular streaming services\n",
        "            if isinstance(watch_providers, float):\n",
        "              watch_providers = \"\"\n",
        "            filtered_watch_providers = [provider.strip() for provider in watch_providers.split(',') \n",
        "                            if any(popular.lower() in provider.lower() for popular in popular_streaming_services)]\n",
        "            formatted_watch_providers = \", \".join(filtered_watch_providers)\n",
        "            # Add all information to list of recommendations\n",
        "            recommendations.append((movie_name, genre_str, avg_rating, formatted_watch_providers))\n",
        "    \n",
        "    print(f\"ðŸŽ¬ Using matched movie: {title}\\n\")\n",
        "    print(f\"ðŸ“Œ Top {num_recs} movies similar to '{title}':\")\n",
        "    \n",
        "    # Print out movie information for each recommendation in formatted way\n",
        "    for i, (movie_name, genre, rating, watch_providers) in enumerate(recommendations, start=1):\n",
        "        print(f\"{i}. {movie_name} (Genre: {genre}, Rating: {rating})\")\n",
        "        print(f\"   ðŸ“º Where to stream: {watch_providers}\")\n",
        "        print()"
      ],
      "id": "80d4b392",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function above takes in a movie title, and prints out the top 10 movies that are most similar to that input movie based on user rating patterns. Let's try out this function on the best picture winner from this years Oscars.\n"
      ],
      "id": "faa22845"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "collaborative_based_movie_recs('Anora', movies_pivot, movies_merged, knn, num_recs=10)"
      ],
      "id": "e883c66e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the genres and other content based features of the movies might not line up because this recommendation system is not based on what the movie is actually about. It is recommending movies based on how different users rated it, so they could be very different movies, but still get similar numeric ratings across users.\n",
        "\n",
        "### Hybrid Filtering System\n",
        "\n",
        "To incorporate both the content based and collaborative based recommender systems, a cascade approach is implemented here. This method effectively combines both recommender systems for movies that have reviews available in the dataset, in order to give the user a more complete and holistic movie recommendation.\n",
        "\n",
        "**Implementation Steps:**\\\n",
        "1. **Extract top 100 content based recommendations**\n",
        "\n",
        "-   Using the `content_based_movie_recs` function, find the top 100 movies\n",
        "\n",
        "2\\. **Check if movie has reviews**\n",
        "\n",
        "-   See if the movie id for the movie that recommendations are wanted for is in the reviews DataFrame\n",
        "\n",
        "-   This tells us which branch of our pipeline to follow next\n",
        "\n",
        "3\\. **If the movie has reviews**\n",
        "\n",
        "-   Feed the top 100 content based movie recommendations into `collaborative_based_movie_recs`\n",
        "-   Extract and display the top 10 user rating based movie recommendations for the user\n",
        "\n",
        "4\\. **If the movie does not have reviews available**\n",
        "\n",
        "-   Display the top 10 content based movie recommendations for the user\n"
      ],
      "id": "b4cd02c2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def final_movie_recs(title):\n",
        "  # Retrieve top 100 content based recommendations\n",
        "  top_100_movies = content_based_movie_recs(title, movie_content_df, cosine_sim, top_n=101)\n",
        "  \n",
        "  # List only popular streaming services to include\n",
        "  popular_streaming_services = [\n",
        "    'Netflix', 'Amazon Prime Video', 'Hulu', 'Disney+', 'Apple TV', 'HBO Max', \n",
        "    'YouTube', 'Google Play Movies', 'Peacock', 'Paramount+',\n",
        "    'Max', 'Mubi', 'Amazon Video', 'Netflix basic with Ads', 'Hoopla', 'Vudu']\n",
        "      \n",
        "  # Extract row with movie content for given movie\n",
        "  movie_row = movie_content_df[movie_content_df[\"title\"] == title]\n",
        "  \n",
        "  # Check if movie exists in content DataFrame\n",
        "  if not movie_row.empty:\n",
        "    # Add movie to top 100 DataFrame so that this can be fed into other recommender\n",
        "    top_100_movies = pd.concat([top_100_movies, movie_row], ignore_index=True)\n",
        "  # If movie does not exist in contet DataFrame, let user know\n",
        "  elif movie_row.empty:\n",
        "    return f\"Movie '{title}' not found in the dataset.\"\n",
        "  \n",
        "  # Extract specific movie id\n",
        "  movie_id = movie_row[\"movie_id\"].values[0] if not movie_row.empty else None\n",
        "  \n",
        "  # Check if movie does not have reviews in the reviews DataFrame\n",
        "  if movie_id not in movie_reviews_df[\"movie_id\"].values:\n",
        "      # Extract movie id and title of given movie\n",
        "      input_movie_id = movie_row[\"movie_id\"].values[0]\n",
        "      input_movie_title = movie_row[\"title\"].values[0]\n",
        "      \n",
        "      # Remove the given movie from top 100 movies DataFrame\n",
        "      top_100_movies = top_100_movies[\n",
        "            (top_100_movies[\"movie_id\"] != input_movie_id) & \n",
        "            (top_100_movies[\"title\"] != input_movie_title)]\n",
        "      \n",
        "      print(f\"ðŸŽ¬ Using matched movie: {input_movie_title}\\n\")\n",
        "      print(f\"ðŸ“Œ Top 10 movies similar to '{input_movie_title}':\")\n",
        "      \n",
        "      # Format and print top 10 rows of the top 100 DataFrame\n",
        "      for counter, (i, row) in enumerate(top_100_movies.head(10).iterrows(), 1):\n",
        "        # Extract genre id for each movie\n",
        "        genres = row['genre_ids']\n",
        "        # If genre is a string, convert to list and format to joined string for printing\n",
        "        if isinstance(genres, str):\n",
        "            genres = eval(genres)\n",
        "        genres = ', '.join(genres)\n",
        "        print(f\"{counter}. {row['title']} (Genre: {genres}, Rating: {row['rating_average']:.2f})\")\n",
        "        \n",
        "        # Select and format only the popular watch providers\n",
        "        available_providers = [provider for provider in row['watch_providers'].split(', ') if provider in popular_streaming_services]\n",
        "        \n",
        "        # Print out all available streaming services\n",
        "        if available_providers:\n",
        "            print(f\"   ðŸ“º Where to stream: {', '.join(available_providers)}\")\n",
        "        print()\n",
        "  \n",
        "  # If movie does have reviews in the reviews DataFrame\n",
        "  else:\n",
        "    # Select all unique movies in the top 100 content based recommendations\n",
        "    movie_ids_set = set(top_100_movies[\"movie_id\"])\n",
        "    # Subset movies_df to include only the top 100 movies \n",
        "    movies_subset = movies_df[movies_df[\"id\"].isin(movie_ids_set)]\n",
        "    # Subset movie_reviews_df to incude only the top 100 movies\n",
        "    reviews_subset = movie_reviews_df[movie_reviews_df[\"movie_id\"].isin(movie_ids_set)]\n",
        "    # Merge both subsetted DataFrames: movies and their reviews\n",
        "    movies_merged = movies_subset.merge(reviews_subset, left_on=\"id\", right_on=\"movie_id\")\n",
        "    \n",
        "    # Pivot the merged table so that rows are movies, columns are users, values are those users ratings\n",
        "    movies_pivot = movies_merged.pivot_table(index=\"title\",columns=\"id\",values=\"user_rating\").fillna(0)\n",
        "    \n",
        "    # Create Compressed Sparse Row (CSR) matrix of pivoted table\n",
        "    movies_matrix = csr_matrix(movies_pivot.values)\n",
        "    \n",
        "    # Fit KNN model with cosine similarity as distance metric\n",
        "    knn = NearestNeighbors(metric = \"cosine\", algorithm = \"brute\")\n",
        "    knn.fit(movies_matrix)\n",
        "    \n",
        "    # Run top 100 recs through collaborative recommender to get top 10 recommendations\n",
        "    final_recommendations = collaborative_based_movie_recs(title, movies_pivot, movies_merged, knn, num_recs=10)\n",
        "    \n",
        "    return final_recommendations"
      ],
      "id": "94808c2b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function defined above will retrieve the final top 10 movie recommendations for a given movie, based on content and reviews if that data is present. Let's see what results we get for the same movie as before.\n"
      ],
      "id": "d6f4fe33"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "final_movie_recs(\"Anora\")"
      ],
      "id": "12461df2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These top ten recommendations are different than the collaborative and content based recommendations for this movie because now it is using a combination of the two recommender systems. It begins by narrowing down from a list of 4,000 movies to only the top 100 that have similar genres, casts, and watch providers. From there, those top 100 are filtered down to the top 10 movies that were rated similar to Anora.\n",
        "\n",
        "### Evaluation\n",
        "\n",
        "It is difficult to evaluate the performance of these models since movie recommendations will be subjective, but as people who have a general understanding of movies, they look to be giving solid recommendations. For the content based approach, since we recommended based on movie genre, cast, and watch providers, the recommendations with generally be movies that fall under similar genres and casting. On the other hand, the collaborative based approach depends mostly on the user review data that you are working with. Since user reviews are all subjective to what the reviewer themself thinks, the movies that are recommended based on their reviews will change with the data that is given. Since there were only 1668 movies that had ample reviews and movie content data, that led to our hybrid recommender model pipeline including a more well rounded recommendation for those movies since we were able to incorporate the user rating aspect into those as well. But due to the gap in the datasets, a lot of movies will only get the content based recommendations for their top 10 most similar movies.\n",
        "\n",
        "## Results and Analysis\n",
        "\n",
        "Our content-based recommendation system produces results using cosine similarity and linear kernel similarity, each with distinct advantages. Cosine similarity, which relies solely on text-based features like genres and cast, tends to recommend movies with similar themes and stylistic elements. In contrast, linear kernel similarity, which incorporates numerical features like `rating_average` and `vote_count`, generates recommendations that balance thematic similarity with popularity. One challenge we encountered was the cold start problemâ€”movies with missing metadata or low visibility were harder to match accurately. To mitigate this, we ensured that movies without cast or provider information still had their genres factored into similarity calculations. However, content-based filtering remains limited in personalization since it does not account for user preferences.\n",
        "\n",
        "To improve upon our content based recommendations, we also implement a collaborative based recommender system. The strengths of this method compared to content based are that it can give more nuanced recommendations beyond just having the same genre or same lead actor. It can suggest a movie for a user even if the content features of the movie do not line up. For example, if a group of users really love one movie because maybe it is really artistic, they might rate a movie of a completely different genre high as well due to its artistry, which would warrant a recommendation. The weaknesses of this system are the data that the model is trained on because it needs to be very representative of all users across all different types of movies, and ideally have ample reviews for each movie and each user. With better data, come better recommendations for each movie because there is more to be known about how different users received these movies compared to other ones.\n",
        "\n",
        "To get the best of both worlds for the finalized recommender system, we implemented a hybrid cascade approach that was able to integrate both content and collaborative based recommendations. This system will give the most well rounded recommendations because it is taking into account content features of the film, as well as how users rated it. The drawbacks to this approach are that not every single movie that has content data also has user rating data. Of the 4,000 unique movies in `movies_df`, only 1,668 of them also had data on their reviews. This led to the partially cascade approach of the finalized recommender system, which included collaborative recommendations for the movies that had ample review data. In the future, we could ideally collect enough user rating data to span across all movies in the content DataFrame so that the final hybrid recommendation was able to take both methods into account.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "-   Summarize the project's achievements.\n",
        "\n",
        "-   Suggest potential improvements (e.g., hybrid models, enhanced data sources, or improved user interface).\n",
        "\n",
        "-   Mention real-world applications or extensions of the system.\n",
        "\n",
        "We built a content-based filtering system that recommends movies based on their attributes rather than user interactions. Using TF-IDF vectorization, we transformed movie metadata into numerical representations and applied cosine similarity and linear kernel similarity to measure similarity. The model effectively finds movies with similar genres and cast but has some limitations such as inability to suggest nuanced recommendations. We also implemented a collaborative based filtering system that took into account movies that had gotten similar rating patterns by different users. The two models were then combined to create a hybrid cascade recommender system that could give well rounded and diverse recommendations for users based on a movie that they want recommendations for. To improve upon the model we created, we could include other content features like directors, producers, or use Natural Language Processing to analyze the movie summary or user reviews. We also could look into refining feature weights so that certain aspects are taken into account more than others, and also acquiring data about the user seeking recommendations so the system can offer a more personalized list of recommendations. Overall, these recommender systems effectively produce movie recommendations based on both content and user ratings, but improvements could be made for the future to offer more personalized and nuanced recommendations."
      ],
      "id": "b9d003b5"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/valeriedelafuente/.virtualenvs/r-reticulate/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}